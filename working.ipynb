{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166b663d-8161-45fc-b40e-bea8d239dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from blockulib.classess import PlayingLoop\n",
    "import blockulib.models as blom\n",
    "import blockulib\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ebc424-38aa-4c6c-9eb5-44271fc688ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelBasedLoop(PlayingLoop):\n",
    "    \n",
    "    def __init__(self, model_path = \"models/conv_model.pth\", architecture = blom.ConvModel):\n",
    "        self.model = architecture()\n",
    "        state_dict = torch.load(model_path)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.generator = blockulib.BlockGenerator()\n",
    "        self.model.eval()\n",
    "        \n",
    "    def __call__(self, num_games = 1, batch_size = 4096, temperature = 1.0, top_k: int = None):\n",
    "        pos_list = [[torch.zeros(9, 9)] for i in range(num_games)]\n",
    "        state = [True for i in range(num_games)]\n",
    "        active_games = num_games\n",
    "        move = 0\n",
    "        \n",
    "        while (active_games > 0):\n",
    "            move += 1\n",
    "            new_index = []\n",
    "            for i in range(num_games):\n",
    "                if state[i]:\n",
    "                    new_index.append(i)\n",
    "            boards = [pos_list[new_index[i]][-1].clone() for i in range(active_games)]\n",
    "            \n",
    "            pos, ind = blockulib.possible_moves(boards, self.generator)\n",
    "            logits = self.get_model_pred(pos, batch_size = batch_size).squeeze(1)\n",
    "            decisions = blockulib.logits_to_choices(logits, ind, active_games, temperature = temperature, top_k = top_k)\n",
    "            \n",
    "            for i in range(active_games):\n",
    "                if (decisions[i] is None):\n",
    "                    state[new_index[i]] = False\n",
    "                    active_games -= 1\n",
    "                else:\n",
    "                    pos_list[new_index[i]].append(pos[decisions[i]])\n",
    "                    \n",
    "        #print(\"ended after \", move, \" moves\")            \n",
    "        return pos_list\n",
    "                    \n",
    "    def get_model_pred(self, data, batch_size, device = None):\n",
    "        if (data.shape[0] == 0):\n",
    "            return torch.tensor([[]])\n",
    "        if device is None:\n",
    "            device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(device)\n",
    "        predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, data.shape[0], batch_size):\n",
    "                batch = data[i:i+batch_size].to(device)\n",
    "                batch = batch.unsqueeze(1)\n",
    "                output = self.model(batch)\n",
    "                predictions.append(output.cpu())\n",
    "            \n",
    "        return torch.cat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "784508bd-7ff7-4865-a9ba-63651657abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probe(ModelBasedLoop):\n",
    "    \n",
    "    def __call__(self, pos_tensor, depth = 15, batch_size = 4096, temperature = 1.0, top_k: int = None):\n",
    "        num_games = pos_tensor.shape[0]\n",
    "        state = [True for i in range(num_games)]\n",
    "        game_length = torch.zeros(num_games)\n",
    "        last_logit = torch.full((num_games, ), float('-inf'))\n",
    "        active_games = num_games\n",
    "        \n",
    "        for d in range(depth):\n",
    "            new_index = []\n",
    "            for i in range(num_games):\n",
    "                if state[i]:\n",
    "                    new_index.append(i)\n",
    "            print(active_games, \" vs \", len(new_index))\n",
    "            boards = [pos_tensor[new_index[i]].clone() for i in range(active_games)]\n",
    "            \n",
    "            pos, ind = blockulib.possible_moves(boards, self.generator)\n",
    "            logits = self.get_model_pred(pos, batch_size = batch_size).squeeze(1)\n",
    "            print(logits.shape)\n",
    "            decisions = blockulib.logits_to_choices(logits, ind, active_games, temperature = temperature, top_k = top_k)\n",
    "            \n",
    "            for i in range(active_games):\n",
    "                if (decisions[i] is None):\n",
    "                    state[new_index[i]] = False\n",
    "                    active_games -= 1\n",
    "                else:\n",
    "                    pos_tensor[new_index[i]] = pos[decisions[i]]\n",
    "                    game_length[new_index[i]] += 1.\n",
    "                    last_logit[new_index[i]] = logits[i]\n",
    "            if (active_games == 0):\n",
    "                print(\"juz?\")\n",
    "                break\n",
    "           \n",
    "        return game_length, last_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8391f5e2-785b-4c27-a57e-c88848489841",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = Probe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "310aaed6-4715-4f23-b81e-29a376f0c65e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "tensor_dir = \"data/tensors/\"\n",
    "x_dict = torch.load(tensor_dir + \"x.pth\")\n",
    "x = x_dict['x'][3056:3060]\n",
    "#x = x.unsqueeze(0)\n",
    "x = x.repeat_interleave(10, dim=0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aacb4da-f338-4ff5-89ba-46af14b589bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSearch(ModelBasedLoop):\n",
    "    def __init__(self):\n",
    "        super().__init__(...)\n",
    "        self.probe = Probe()\n",
    "    \n",
    "    def get_model_pred(self, data, batch_size, device = None):\n",
    "        with torch.no_grad():E\n",
    "            for i in range(0, data.shape[0], batch_size):\n",
    "                batch = data[i:i+batch_size].to(device)\n",
    "                batch = batch.unsqueeze(1)\n",
    "                output = self.model(batch)\n",
    "                predictions.append(output.cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
